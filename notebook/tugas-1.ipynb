{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import findspark\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SparkSession\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x0000006D8F8ACB38>\n"
     ]
    }
   ],
   "source": [
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "df = spark.read.csv(\"new_york_tree_census_1995.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "516989"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out dataset's length\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(recordid=433600, address='73-031 57 AV', house_number='73-031', street='57 AV', zip_original=11378, cb_original=405, site='Front', species='QUPA', diameter=6, status='Good', wires='Yes', sidewalk_condition='Good', support_structure='None', borough='Queens', x=1015198.8, y=204725.3752, longitude=-73.888337, latitude=40.728546, cb_new=405, zip_new=11378, censustract_2010='49302', censusblock_2010='2000', nta_2010='QN30', segmentid=74525, spc_common='OAK PIN', spc_latin='QUERCUS PALUSTRIS', location='(40.728546 -73.888337)')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out attributes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(recordid,IntegerType,true),StructField(address,StringType,true),StructField(house_number,StringType,true),StructField(street,StringType,true),StructField(zip_original,IntegerType,true),StructField(cb_original,IntegerType,true),StructField(site,StringType,true),StructField(species,StringType,true),StructField(diameter,IntegerType,true),StructField(status,StringType,true),StructField(wires,StringType,true),StructField(sidewalk_condition,StringType,true),StructField(support_structure,StringType,true),StructField(borough,StringType,true),StructField(x,DoubleType,true),StructField(y,DoubleType,true),StructField(longitude,DoubleType,true),StructField(latitude,DoubleType,true),StructField(cb_new,IntegerType,true),StructField(zip_new,IntegerType,true),StructField(censustract_2010,StringType,true),StructField(censusblock_2010,StringType,true),StructField(nta_2010,StringType,true),StructField(segmentid,IntegerType,true),StructField(spc_common,StringType,true),StructField(spc_latin,StringType,true),StructField(location,StringType,true)))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out each schema\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create alias table to work on as 'trees'\n",
    "df.createOrReplaceTempView(\"trees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+\n",
      "|species|average_diameter|\n",
      "+-------+----------------+\n",
      "|   FRQU|         39.0 cm|\n",
      "|   QUFA|         33.0 cm|\n",
      "|   CAOV|         31.0 cm|\n",
      "|   SAMA|         31.0 cm|\n",
      "|  POTR2|         29.0 cm|\n",
      "|   QUMU|         25.0 cm|\n",
      "|   SYCU|         25.0 cm|\n",
      "|   ULPR|         24.0 cm|\n",
      "|   ULPU|         24.0 cm|\n",
      "|   CAGL|         22.0 cm|\n",
      "|   PRAV|         22.0 cm|\n",
      "|   QUAU|         21.0 cm|\n",
      "|   AEOC|         21.0 cm|\n",
      "|   LITU|         20.0 cm|\n",
      "|   SAPE|         19.0 cm|\n",
      "|   GRRO|         19.0 cm|\n",
      "|   PLAC|         19.0 cm|\n",
      "|   CAPU|         18.0 cm|\n",
      "|   AEHI|         18.0 cm|\n",
      "|   PLRU|         18.0 cm|\n",
      "+-------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the average diameter for each species\n",
    "query1 = spark.sql(\"SELECT species, CONCAT(ROUND(AVG(diameter)), ' cm') AS average_diameter\\\n",
    "                    FROM trees\\\n",
    "                    GROUP BY species\\\n",
    "                    ORDER BY AVG(diameter) DESC\")\n",
    "query1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+\n",
      "|species|   status|total|\n",
      "+-------+---------+-----+\n",
      "|     AB|     Good|  138|\n",
      "|     AB|Excellent|   34|\n",
      "|     AB|     Poor|   16|\n",
      "|     AB|     Dead|    4|\n",
      "|     AB|  Unknown|    4|\n",
      "|     AB|    Shaft|    2|\n",
      "|   ABBA|     Good|    3|\n",
      "|   ABBA|Excellent|    2|\n",
      "|   ABCO|     Good|    3|\n",
      "|     AC|     Good|  388|\n",
      "|     AC|Excellent|  251|\n",
      "|     AC|     Poor|  107|\n",
      "|     AC|     Dead|   32|\n",
      "|     AC|  Unknown|   17|\n",
      "|     AC|     Fair|   11|\n",
      "|     AC|    Shaft|    1|\n",
      "|     AC|    Stump|    1|\n",
      "|   ACAU|     Good|    4|\n",
      "|   ACAU|Excellent|    1|\n",
      "|   ACBU|     Good|    2|\n",
      "+-------+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find status and total of status for each species and sort it by the total\n",
    "query2 = spark.sql(\"SELECT species, status, COUNT(status) AS total\\\n",
    "                    FROM trees\\\n",
    "                    GROUP BY species, status\\\n",
    "                    ORDER BY species ASC, COUNT(status) DESC\")\n",
    "query2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|      street|total|\n",
      "+------------+-----+\n",
      "|    BROADWAY| 2034|\n",
      "|       78 ST| 1215|\n",
      "|       79 ST| 1186|\n",
      "|        5 AV| 1167|\n",
      "|     PARK AV| 1145|\n",
      "|  BEDFORD AV| 1087|\n",
      "|F LEWIS BLVD| 1062|\n",
      "|       80 ST| 1054|\n",
      "|       81 ST| 1017|\n",
      "| LINDEN BLVD| 1004|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find street with top 10 largest amount of good and excellent trees\n",
    "query3 = spark.sql(\"SELECT street, COUNT(species) AS total\\\n",
    "                    FROM trees\\\n",
    "                    WHERE status IN ('Good', 'Excellent')\\\n",
    "                    GROUP BY street\\\n",
    "                    ORDER BY COUNT(species) DESC\\\n",
    "                    LIMIT 10\")\n",
    "query3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|         street|total|\n",
      "+---------------+-----+\n",
      "|       BROADWAY|  394|\n",
      "|    QUEENS BLVD|  333|\n",
      "|GRAND CONCOURSE|  320|\n",
      "|           2 AV|  199|\n",
      "|           3 AV|  193|\n",
      "|    LINDEN BLVD|  176|\n",
      "|         E 7 ST|  173|\n",
      "|           1 AV|  169|\n",
      "|   EASTERN PKWY|  169|\n",
      "|           5 AV|  147|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find street with top 10 largest amount of poor, dead and unknown trees\n",
    "query4 = spark.sql(\"SELECT street, COUNT(species) AS total\\\n",
    "                    FROM trees\\\n",
    "                    WHERE status IN ('Poor', 'Dead', 'Unknown')\\\n",
    "                    GROUP BY street\\\n",
    "                    ORDER BY COUNT(species) DESC\\\n",
    "                    LIMIT 10\")\n",
    "query4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----+\n",
      "|species|support_structure|total|\n",
      "+-------+-----------------+-----+\n",
      "|     AC|   Stakes / Wires|   43|\n",
      "|   ACCA|   Stakes / Wires|    1|\n",
      "|   ACPA|   Stakes / Wires|   15|\n",
      "|   ACPE|   Stakes / Wires|    5|\n",
      "|   ACPL|   Stakes / Wires| 2572|\n",
      "|   ACPL| Guard Strangling|    2|\n",
      "|   ACPS|   Stakes / Wires|  193|\n",
      "|   ACPS| Guard Strangling|    1|\n",
      "|   ACRU|   Stakes / Wires|  979|\n",
      "|   ACRU| Guard Strangling|    1|\n",
      "|  ACSA1|   Stakes / Wires|  313|\n",
      "|  ACSA1| Guard Strangling|    1|\n",
      "|  ACSA2|   Stakes / Wires|  439|\n",
      "|  ACSA2| Guard Strangling|    3|\n",
      "|   AEHI|   Stakes / Wires|    6|\n",
      "|   AIAL|   Stakes / Wires|  190|\n",
      "|   AIAL| Guard Strangling|    2|\n",
      "|   ALJU|   Stakes / Wires|    1|\n",
      "|     BE|   Stakes / Wires|   20|\n",
      "|   BENI|   Stakes / Wires|    1|\n",
      "+-------+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find species with required support structure and its total\n",
    "query5 = spark.sql(\"SELECT species, support_structure, COUNT(species) AS total\\\n",
    "                    FROM trees\\\n",
    "                    WHERE support_structure <> 'None'\\\n",
    "                    GROUP BY species, support_structure\\\n",
    "                    ORDER BY species, COUNT(species) DESC\")\n",
    "query5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-----+\n",
      "|species|         site|total|\n",
      "+-------+-------------+-----+\n",
      "|     AB|     Assigned|   11|\n",
      "|     AB|         Side|   58|\n",
      "|     AB|       Median|    2|\n",
      "|     AB|     Adjacent|   26|\n",
      "|     AB|        Front|   99|\n",
      "|     AB|       Across|    2|\n",
      "|   ABBA|       Across|    1|\n",
      "|   ABBA|        Front|    2|\n",
      "|   ABBA|         Side|    2|\n",
      "|   ABCO|        Front|    1|\n",
      "|   ABCO|     Adjacent|    1|\n",
      "|   ABCO|         Side|    1|\n",
      "|     AC|     Assigned|   23|\n",
      "|     AC|       Across|   44|\n",
      "|     AC|     Adjacent|  134|\n",
      "|     AC|         Side|  191|\n",
      "|     AC|Side/Adjacent|    1|\n",
      "|     AC|       Median|    1|\n",
      "|     AC|  Median/Side|    2|\n",
      "|     AC|        Front|  407|\n",
      "+-------+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show species and where it's sited along with the total\n",
    "query6 = spark.sql(\"SELECT species, site, COUNT(site) AS total\\\n",
    "                    FROM trees\\\n",
    "                    GROUP BY species, site\\\n",
    "                    ORDER BY species\")\n",
    "query6.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+--------------------+\n",
      "|           address|species|            location|\n",
      "+------------------+-------+--------------------+\n",
      "|   0 ROCKAWAY FRWY|   PLAC|-73.760559, 40.60...|\n",
      "|   0 ROCKAWAY FRWY|UNKDEAD|-73.760559, 40.60...|\n",
      "|            1 2 AV|UNKNOWN|-73.991008, 40.67...|\n",
      "|            1 2 AV|   QUPA|-73.991008, 40.67...|\n",
      "|            1 2 AV|   QURU|-73.991008, 40.67...|\n",
      "|            1 5 AV|UNKDEAD|-73.839771, 40.79...|\n",
      "|       1 ADRIAN AV|   TICO|-73.912754, 40.87566|\n",
      "|    1 ASPINWALL ST|   PLAC|-74.24948, 40.508272|\n",
      "|     1 BELMONT TER|  ACSA1|-74.081925, 40.64403|\n",
      "|        1 BROWN PL|   MORU|-74.067776, 40.60...|\n",
      "|       1 BUTLER ST|   FRAM|-73.994541, 40.68...|\n",
      "|     1 CAROLINA RD|   ACPL|            1.0, 1.0|\n",
      "|     1 CARTERET ST|   PLAC|-74.24847, 40.508581|\n",
      "|         1 CASE AV|   QUPA|-74.195214, 40.51...|\n",
      "|         1 CASE AV|  ACSA1|-74.195214, 40.51...|\n",
      "|1 COLUMBIA HEIGHTS|   GLTR|-73.999569, 40.69...|\n",
      "|     1 COLUMBUS AV|   ACPS|-74.092817, 40.60...|\n",
      "|   1 CONYINGHAM AV|   PLAC|-74.103132, 40.63...|\n",
      "|        1 CYRUS AV|   QURU|-73.926842, 40.58...|\n",
      "|     1 DRIPROCK ST|   PLAC|-74.128212, 40.63...|\n",
      "+------------------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the address of tree and its species that touches wires (power line) along with its location\n",
    "query7 = spark.sql(\"SELECT DISTINCT address, species, CONCAT(longitude, ', ', latitude) AS location\\\n",
    "                    FROM trees\\\n",
    "                    WHERE wires <> 'None'\\\n",
    "                    ORDER BY address\")\n",
    "query7.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+------------------+--------------------+\n",
      "|           address|species|sidewalk_condition|            location|\n",
      "+------------------+-------+------------------+--------------------+\n",
      "|        1 ASCAN AV|   SOJA|                NA|            1.0, 1.0|\n",
      "|        1 ASCAN AV|   QURU|            Raised|            1.0, 1.0|\n",
      "|        1 ASCAN AV|   QURU|                NA|            1.0, 1.0|\n",
      "|        1 ASCAN AV|   PRMA|                NA|            1.0, 1.0|\n",
      "|       1 BUTLER ST|   FRAM|            Raised|-73.994541, 40.68...|\n",
      "|       1 BUTLER ST|   PLAC|            Raised|-73.994541, 40.68...|\n",
      "|     1 CARTERET ST|   PLAC|            Raised|-74.24847, 40.508581|\n",
      "| 1 CO OP CITY BLVD|   FRPE|                NA|            1.0, 1.0|\n",
      "| 1 CO OP CITY BLVD|   GLTR|                NA|            1.0, 1.0|\n",
      "|1 COLUMBIA HEIGHTS|   GLTR|            Raised|-73.999569, 40.69...|\n",
      "|         1 E 21 ST|   GIBI|                NA|-73.990502, 40.74...|\n",
      "|        1 E 233 ST|   QUPA|            Raised|-73.879776, 40.89...|\n",
      "|      1 ELTINGE ST|   ACPL|            Raised|-74.094537, 40.60...|\n",
      "|          1 FOX ST|   QUPA|            Raised|-73.84409, 40.872653|\n",
      "|   1 FT CHARLES PL|     AC|            Raised|-73.911425, 40.87...|\n",
      "|       1 GEORGE ST|   PLAC|            Raised|-73.932761, 40.70...|\n",
      "|        1 GRACE CT|UNKNOWN|            Raised| -73.9986, 40.694529|\n",
      "|       1 HOLMES LA|   PLAC|            Raised|-73.898045, 40.63...|\n",
      "|   1 MONTGOMERY PL|   PLAC|            Raised|-73.974153, 40.67...|\n",
      "| 1 PAERDEGAT 14 ST|   ACPL|            Raised|-73.902399, 40.62...|\n",
      "+------------------+-------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show address and its location which has either good or excellent tree but not good sidewalk condition\n",
    "query8 = spark.sql(\"SELECT DISTINCT address, species, sidewalk_condition, CONCAT(longitude, ', ', latitude) AS location\\\n",
    "                    FROM trees\\\n",
    "                    WHERE sidewalk_condition <> 'Good' AND status IN ('Good', 'Excellent')\\\n",
    "                    ORDER BY address\")\n",
    "query8.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the Results\n",
    "#### Let's say we'd like to export the result of query8 above to CSV, either as partitioned ones or as a whole data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results of query8 to partitioned csv forms\n",
    "query8.write \\\n",
    "      .option(\"header\", \"true\") \\\n",
    "      .csv(\"file:///C:/Users/Nuzha Musyafira/Documents/github/big-data/result/query8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the result into pandas dataframe then save it as single csv file\n",
    "pd_query8 = query8.toPandas()\n",
    "pd_query8.to_csv(\"C:/Users/Nuzha Musyafira/Documents/github/big-data/result/pd-query8.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
